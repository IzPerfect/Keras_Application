{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras.layers import Dense, Activation, Conv2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net():\n",
    "    model = models.Sequential()\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', input_shape = (28, 28, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 0.001)\n",
    "                          ,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = build_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model after train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory\n",
    "save_dir = './save_model/'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 20s 331us/step - loss: 0.2279 - acc: 0.9348\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 23s 380us/step - loss: 0.0871 - acc: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffc2a96d68>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net.fit(x_train, y_train, batch_size = 32, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The save () function stores both the structure and the weight of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net.save(save_dir + 'save_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saved model reuse using load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model architecture and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(save_dir + 'save_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                125450    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 125,610\n",
      "Trainable params: 125,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The get_config () function shows detailed configuration information for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'class_name': 'Conv2D',\n",
       "   'config': {'activation': 'linear',\n",
       "    'activity_regularizer': None,\n",
       "    'batch_input_shape': (None, 28, 28, 1),\n",
       "    'bias_constraint': None,\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'bias_regularizer': None,\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'dtype': 'float32',\n",
       "    'filters': 16,\n",
       "    'kernel_constraint': None,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'distribution': 'uniform',\n",
       "      'mode': 'fan_avg',\n",
       "      'scale': 1.0,\n",
       "      'seed': None}},\n",
       "    'kernel_regularizer': None,\n",
       "    'kernel_size': (3, 3),\n",
       "    'name': 'conv2d_1',\n",
       "    'padding': 'same',\n",
       "    'strides': (1, 1),\n",
       "    'trainable': True,\n",
       "    'use_bias': True}},\n",
       "  {'class_name': 'Activation',\n",
       "   'config': {'activation': 'relu',\n",
       "    'name': 'activation_1',\n",
       "    'trainable': True}},\n",
       "  {'class_name': 'Flatten',\n",
       "   'config': {'data_format': 'channels_last',\n",
       "    'name': 'flatten_1',\n",
       "    'trainable': True}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'activation': 'linear',\n",
       "    'activity_regularizer': None,\n",
       "    'bias_constraint': None,\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'bias_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'distribution': 'uniform',\n",
       "      'mode': 'fan_avg',\n",
       "      'scale': 1.0,\n",
       "      'seed': None}},\n",
       "    'kernel_regularizer': None,\n",
       "    'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'units': 10,\n",
       "    'use_bias': True}},\n",
       "  {'class_name': 'Activation',\n",
       "   'config': {'activation': 'softmax',\n",
       "    'name': 'activation_2',\n",
       "    'trainable': True}}],\n",
       " 'name': 'sequential_1'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0910824e-09, 2.1872920e-10, 7.2590318e-08, ..., 9.9997354e-01,\n",
       "        3.2753408e-07, 5.3104918e-06],\n",
       "       [1.8211487e-05, 9.4478550e-05, 9.9955171e-01, ..., 1.0896243e-14,\n",
       "        7.2268574e-07, 6.6417168e-13],\n",
       "       [2.2806544e-05, 9.9760652e-01, 4.5086499e-04, ..., 9.3125587e-04,\n",
       "        5.0584809e-04, 6.3833381e-06],\n",
       "       ...,\n",
       "       [1.9720436e-09, 8.5637328e-09, 1.9384997e-08, ..., 1.4988969e-04,\n",
       "        3.2159423e-05, 2.6284895e-04],\n",
       "       [8.0302407e-08, 7.8227309e-09, 5.0307363e-09, ..., 2.6371936e-09,\n",
       "        4.2345829e-04, 1.0097833e-08],\n",
       "       [2.5761246e-08, 7.1552424e-11, 2.8835304e-06, ..., 7.2816163e-11,\n",
       "        1.0451320e-07, 2.5249899e-10]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 163us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07690361095573753, 0.9769]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and reuse only weight values from saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net_only_weights = build_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net_only_weights.load_weights(save_dir + 'save_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0910824e-09, 2.1872920e-10, 7.2590318e-08, ..., 9.9997354e-01,\n",
       "        3.2753408e-07, 5.3104918e-06],\n",
       "       [1.8211487e-05, 9.4478550e-05, 9.9955171e-01, ..., 1.0896243e-14,\n",
       "        7.2268574e-07, 6.6417168e-13],\n",
       "       [2.2806544e-05, 9.9760652e-01, 4.5086499e-04, ..., 9.3125587e-04,\n",
       "        5.0584809e-04, 6.3833381e-06],\n",
       "       ...,\n",
       "       [1.9720436e-09, 8.5637328e-09, 1.9384997e-08, ..., 1.4988969e-04,\n",
       "        3.2159423e-05, 2.6284895e-04],\n",
       "       [8.0302407e-08, 7.8227309e-09, 5.0307363e-09, ..., 2.6371936e-09,\n",
       "        4.2345829e-04, 1.0097833e-08],\n",
       "       [2.5761246e-08, 7.1552424e-11, 2.8835304e-06, ..., 7.2816163e-11,\n",
       "        1.0451320e-07, 2.5249899e-10]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net_only_weights.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 191us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07690361095573753, 0.9769]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net_only_weights.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 22s 375us/step - loss: 0.2010 - acc: 0.9426\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 21s 345us/step - loss: 0.0755 - acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffc5375b38>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net_save_only_weights = build_net()\n",
    "mnist_net_save_only_weights.fit(x_train, y_train, batch_size = 32, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 171us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06776213491801172, 0.9791]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net_save_only_weights.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save_weights save only weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net_save_only_weights.save_weights(save_dir + 'save_only_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net_save_only_weights_reuse = build_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load only weights and evaluate loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net_save_only_weights_reuse.load_weights(save_dir + 'save_only_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 202us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06776213491801172, 0.9791]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net_save_only_weights_reuse.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model as json format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model information can be converted to json format and stored in memory as string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_json = build_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_json_model = mnist_json.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"keras_version\": \"2.2.4\", \"config\": {\"name\": \"sequential_5\", \"layers\": [{\"class_name\": \"Conv2D\", \"config\": {\"kernel_constraint\": null, \"bias_regularizer\": null, \"name\": \"conv2d_5\", \"kernel_regularizer\": null, \"filters\": 16, \"dtype\": \"float32\", \"strides\": [1, 1], \"dilation_rate\": [1, 1], \"activation\": \"linear\", \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"use_bias\": true, \"bias_constraint\": null, \"padding\": \"same\", \"activity_regularizer\": null, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"trainable\": true, \"batch_input_shape\": [null, 28, 28, 1], \"kernel_size\": [3, 3], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_9\", \"trainable\": true, \"activation\": \"relu\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten_5\", \"trainable\": true, \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"bias_regularizer\": null, \"units\": 10, \"kernel_regularizer\": null, \"name\": \"dense_5\", \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"use_bias\": true, \"bias_constraint\": null, \"activity_regularizer\": null, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"trainable\": true, \"activation\": \"linear\", \"kernel_constraint\": null}}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_10\", \"trainable\": true, \"activation\": \"softmax\"}}]}, \"class_name\": \"Sequential\", \"backend\": \"tensorflow\"}\n"
     ]
    }
   ],
   "source": [
    "print(mnist_json_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json file write to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_dir + \"/mnist_json_model.json\", \"w\") as json_file : \n",
    "    json_file.write(mnist_json_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json format model information can be reloaded and reused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load json and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file from path\n",
    "json_file = open(save_dir + \"/mnist_json_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close()\n",
    "\n",
    "# load model from json file\n",
    "saved_mnist_json_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load cnn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_mnist_json_model.load_weights(save_dir + 'save_only_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model information of json format should be compiled again after model load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes the compile condition the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json format should be compiled\n",
    "saved_mnist_json_model.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 0.001)\n",
    "                          ,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 165us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06776213491801172, 0.9791]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_mnist_json_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model save using callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = save_dir + '{epoch:02d}-{val_loss:.4f}-{acc:.4f}.hd5'\n",
    "\n",
    "# Only when val_loss is lower than before\n",
    "cb_checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 21s 429us/step - loss: 0.2187 - acc: 0.9369 - val_loss: 0.1053 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10525, saving model to ./save_model/01-0.1053-0.9369.hd5\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 17s 364us/step - loss: 0.0832 - acc: 0.9757 - val_loss: 0.0865 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10525 to 0.08648, saving model to ./save_model/02-0.0865-0.9757.hd5\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 18s 371us/step - loss: 0.0579 - acc: 0.9828 - val_loss: 0.0778 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08648 to 0.07777, saving model to ./save_model/03-0.0778-0.9828.hd5\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 18s 380us/step - loss: 0.0448 - acc: 0.9863 - val_loss: 0.0810 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07777\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 21s 435us/step - loss: 0.0357 - acc: 0.9891 - val_loss: 0.0809 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07777\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 18s 373us/step - loss: 0.0279 - acc: 0.9919 - val_loss: 0.0777 - val_acc: 0.9795\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07777 to 0.07766, saving model to ./save_model/06-0.0777-0.9919.hd5\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 19s 405us/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0848 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07766\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 20s 413us/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.0848 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07766\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 23s 481us/step - loss: 0.0147 - acc: 0.9956 - val_loss: 0.0837 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07766\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 19s 394us/step - loss: 0.0118 - acc: 0.9966 - val_loss: 0.0872 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffc593e710>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_save_model = build_net()\n",
    "best_save_model.fit(x_train, y_train,validation_split = 0.2, batch_size = 32, epochs = 10, callbacks = [cb_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If a model with the highest performance is found in the beginning, and a model with better performance is no longer found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 18s 373us/step - loss: 0.2190 - acc: 0.9376 - val_loss: 0.0993 - val_acc: 0.9722\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 18s 368us/step - loss: 0.0822 - acc: 0.9755 - val_loss: 0.0818 - val_acc: 0.9752\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 19s 387us/step - loss: 0.0573 - acc: 0.9832 - val_loss: 0.0768 - val_acc: 0.9778\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 20s 410us/step - loss: 0.0451 - acc: 0.9860 - val_loss: 0.0774 - val_acc: 0.9778\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 18s 383us/step - loss: 0.0362 - acc: 0.9887 - val_loss: 0.0824 - val_acc: 0.9771\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 22s 468us/step - loss: 0.0293 - acc: 0.9908 - val_loss: 0.0741 - val_acc: 0.9805\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 21s 436us/step - loss: 0.0233 - acc: 0.9927 - val_loss: 0.0859 - val_acc: 0.9783\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 22s 456us/step - loss: 0.0189 - acc: 0.9942 - val_loss: 0.0832 - val_acc: 0.9798\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 20s 408us/step - loss: 0.0147 - acc: 0.9956 - val_loss: 0.0867 - val_acc: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffc5c028d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if val_loss can not increase in 3 patience(epochs), stop training\n",
    "cb_early_stopping = EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "\n",
    "# create model\n",
    "earlystopping_model = build_net()\n",
    "earlystopping_model.fit(x_train, y_train,validation_split = 0.2, batch_size = 32, epochs = 10, callbacks = [cb_early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best model save + early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = build_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 19s 394us/step - loss: 0.2337 - acc: 0.9324 - val_loss: 0.1091 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.07766\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 19s 390us/step - loss: 0.0869 - acc: 0.9746 - val_loss: 0.0874 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07766\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 20s 426us/step - loss: 0.0602 - acc: 0.9826 - val_loss: 0.0766 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07766 to 0.07658, saving model to ./save_model/03-0.0766-0.9826.hd5\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 20s 416us/step - loss: 0.0463 - acc: 0.9862 - val_loss: 0.0826 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07658\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 20s 408us/step - loss: 0.0373 - acc: 0.9885 - val_loss: 0.0821 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07658\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 20s 408us/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.0836 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffe368c860>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit(x_train, y_train,validation_split = 0.2, batch_size = 32, epochs = 10, callbacks = [cb_checkpoint,cb_early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce learning rate when a metric has stopped improving <br>\n",
    "This function monitors that if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "model.fit(X_train, Y_train, callbacks=[reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow35]",
   "language": "python",
   "name": "conda-env-tensorflow35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
